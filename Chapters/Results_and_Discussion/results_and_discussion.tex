\pagestyle{fancy}
\fancyhead{}

\fancyheadoffset{0cm}
\renewcommand{\headrulewidth}{1pt} 
\renewcommand{\footrulewidth}{0pt}
\fancyhead[L]{{\thesection}}
\fancyhead[L]{\leftmark}

% \fancyhead[LO,LE]{\nouppercase\firstleftmark}
%\fancyhead[RO,RE]{\thesubsection\enspace\subsectiontitle}

\section{Results and Discussion}    

\subsection{Analysis on a subset of patients}   \label{res:anal}

!!! Mostrare un paziente (se no diventa troppo lunga come immagini) come in
presentazione mettendo gli altri 3 in appendice

\subsubsection{Feature importance}  \label{res:anal:importance}

!!! Grafico a barre delle features, giustificare la scelta della betweenness come
peso per il classificatore

\subsubsection{Global seizure dynamics}     \label{res:anal:global}

!!! Mostrare tutte e 22 le features, spiegando i trend più evidenti

\subsubsection{A classification example}    \label{res:anal:example}

!!! Far vedere i plot dello spazio latente, della likelihood e 
grafico a barre del segnale d'allarme spiegando cosa succede

\subsection{Optimization Results}       \label{res:opt}

Hyperparameter optimization was performed as described in Section \ref{meth:opt}.
In this section we will present the final parameters,
the distribution of the best parameters for the cross-validation,
the learning curves, and the distributions of the optimization target for
training, validation and test set.
The results presented in this section will be discussed in Section
\ref{res:discussion}.

\subsubsection{VAE and GMM}         \label{res:opt:vaegmm}

Optimization of the VAE and GMM architecture was performed for 300 iterations on
each LOOCV fold.
As discussed in Section \ref{meth:opt} the validation target\footnote{
Rank biserial correlation of one-sided Mann-Whitney test comparing the negative
log-likelihood of SOZ and non-SOZ contacts during a seizure. Refer to Section
\ref{meth:opt:vaegmm} for details.}
on each fold was monitored during training.
The median validation target stopped increasing after iteration 193
(!!! valutare se inserire immagine),
for this reason the final training before evalutating test patients was limited
to 193 iterations.

Figure \ref{fig:opt1_params} shows the best parameters for each LOOCV fold,
while Table \ref{tab:opt1_params} presents the best parameters returned by the
final training procedure.
The learning process of the final training is shown in Figure
\ref{fig:opt1_learn} and Figure \ref{fig:opt1_target} displays the 
target distribution on training, validation and test set.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Immagini/opt/best_params_1.png}
    \caption{Best parameters in cross-validation for VAE and GMM optimization.}
    \label{fig:opt1_params}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Immagini/opt/optimization_curve_1.png}
    \caption{Learning curve in the final training of VAE and GMM optimization.}
    \label{fig:opt1_learn}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Parameter} & \textbf{Best value} \\
\hline
$\beta_\text{max}$     & 1  \\
$\beta_\text{warmup}$  & 10 \\
$d$                    & 2  \\
$\eta$                 & 0.024 \\
$L$                    & 0 \\
$N_c$                  & 2 \\
\hline
\end{tabular}
\caption{Best parameters for the final training of VAE and GMM optimization.}
\label{tab:opt1_params}
\end{table}

\begin{figure}[H]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/opt/contrast_distributions_val.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/opt/contrast_distributions_test.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{Training, validation and test distributions of optimization target 
    for VAE and GMM optimization.}
    \label{fig:opt1_target}
\end{figure}


\subsubsection{Classifier}      \label{res:opt:classifier}

Optimization of the alarm classifier was performed for 200 iterations on
each LOOCV fold.
The median validation target\footnote{
Arithmetic average of precision (PPV) and specificity (SPC) multiplied by a
penalty function. Refer to Section \ref{meth:opt:classifier} for details.}
stopped increasing after iteration 173,
(!!! valutare se inserire immagine),
therefore the final training was limited to 173 iterations.

Figure \ref{fig:opt2_params} shows the best parameters for each LOOCV fold,
while Table \ref{tab:opt2_params} presents the best parameters returned by the
final training procedure.
The learning process of the final training is shown in Figure
\ref{fig:opt2_learn} and Figure \ref{fig:opt2_target} displays the 
target distribution on training, validation and test set.
Because the target for this phase of optimization is itself a binary evaluation
metric, Figure \ref{fig:opf2_target} also reports a comparison with the random
classifier and the automated version of the Epileptogenicity Index proposed by 
Bartolomei et al. \cite{bartolomei}.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Immagini/opt/best_params_2.png}
    \caption{Best parameters in cross-validation for the classifier optimization.}
    \label{fig:opt2_params}
\end{figure}


\begin{table}[H]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Parameter} & \textbf{Best value} \\
\hline
$\alpha$               & 0.96  \\
$k$                    & -2.3 \\
$t_C$                  & 1.8  \\
$\tau$                 & 1.2 \\
\hline
\end{tabular}
\caption{Best parameters for the final training of the classifier optimization.}
\label{tab:opt2_params}
\end{table}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Immagini/opt/optimization_curve_2.png}
    \caption{Learning curve in the final training of the classifier optimization.}
    \label{fig:opt2_learn}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/opt/score_distributions_val.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/opt/score_distributions_test.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{Training, validation and test distributions of optimization target 
    for the classifier optimization.}
    \label{fig:opt2_target}
\end{figure}


\subsection{Evaluation Metrics}     \label{res:eval}

This section reports precision (PPV), specificity (SPC), balanced
accuracy (BA) and ROC-AUC for training, validation and test patients, 
while comparing such distributions with
the results that would obtain a random classifier and the automated version of
the Epileptogenicity Index proposed by Bartolomei et al. \cite{bartolomei}.

Figure \ref{fig:eval} and Table \ref{tab:eval} summarize the evaluation results.
It is important to remind, as explained in Section \ref{meth:opt:classifier},
that the ground truth may label as positive contacts that do not show
epileptogenic behavior in the single seizure that is available for each patient.
For this reason we consider precision and specificity as meaningful statistics
as they do not depend on the number of False Positives.
ROC-AUC and balanced accuracy are reported anyway, however their distributions
may be a conservative estimate of the actual discriminative capabilities of the
model.

!!! Tabella

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_val_set/prec_distributions.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_test_set/prec_distributions.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{Precision (PPV) distributions in training, validation and test set.}
    \label{fig:prec}
\end{figure}

\begin{figure}[H]
\end{figure}
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_val_set/spec_distributions.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_test_set/spec_distributions.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{Specificity (SPC) distributions in training, validation and test set.}
    \label{fig:spec}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_val_set/ba_distributions.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_test_set/ba_distributions.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{Balanced Accuracy (BA) distributions in training, validation and test set.}
    \label{fig:ba}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_val_set/auc_distributions.png}
        \caption{Cross-validation}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{Immagini/eval_test_set/auc_distributions.png}
        \caption{Final training and test}
    \end{subfigure}
    \caption{ROC-AUC distributions in training, validation and test set.}
    \label{fig:auc}
\end{figure}


\subsection{Discussion}         \label{res:discussion}



!!!Confronto con random classifier e Bartolomei


!!! Spiegare perché il training dipende fortemente dai pazienti e i best params
divergono (eterogeneità pazienti, distribuzioni latenti molto ampie)

\subsection{Future developments}              \label{res:discussion:future}

!!! Idee su come migliorare: fine tuning, VAE supervisionato, provare altri
modelli, classificatore deep learning